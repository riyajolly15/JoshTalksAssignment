{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":14886605,"datasetId":9524422,"databundleVersionId":15750137}],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport requests\nimport json\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:46:30.290277Z","iopub.execute_input":"2026-02-19T12:46:30.290778Z","iopub.status.idle":"2026-02-19T12:46:30.352034Z","shell.execute_reply.started":"2026-02-19T12:46:30.290741Z","shell.execute_reply":"2026-02-19T12:46:30.351025Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/datasets/riyajolly/josh-data/FT Data - data.csv\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/datasets/riyajolly/josh-data/FT Data - data.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:46:30.354521Z","iopub.execute_input":"2026-02-19T12:46:30.355126Z","iopub.status.idle":"2026-02-19T12:46:30.408167Z","shell.execute_reply.started":"2026-02-19T12:46:30.355096Z","shell.execute_reply":"2026-02-19T12:46:30.406845Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:46:30.412835Z","iopub.execute_input":"2026-02-19T12:46:30.413131Z","iopub.status.idle":"2026-02-19T12:46:30.443027Z","shell.execute_reply.started":"2026-02-19T12:46:30.413106Z","shell.execute_reply":"2026-02-19T12:46:30.441938Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"   user_id  recording_id language  duration  \\\n0   245746        825780       hi       443   \n1   291038        825727       hi       443   \n2   246004        988596       hi       475   \n3    93626        990175       hi       475   \n4   286851        526266       hi       522   \n\n                                         rec_url_gcp  \\\n0  https://storage.googleapis.com/joshtalks-data-...   \n1  https://storage.googleapis.com/joshtalks-data-...   \n2  https://storage.googleapis.com/joshtalks-data-...   \n3  https://storage.googleapis.com/joshtalks-data-...   \n4  https://storage.googleapis.com/joshtalks-data-...   \n\n                               transcription_url_gcp  \\\n0  https://storage.googleapis.com/joshtalks-data-...   \n1  https://storage.googleapis.com/joshtalks-data-...   \n2  https://storage.googleapis.com/joshtalks-data-...   \n3  https://storage.googleapis.com/joshtalks-data-...   \n4  https://storage.googleapis.com/joshtalks-data-...   \n\n                                    metadata_url_gcp  \n0  https://storage.googleapis.com/joshtalks-data-...  \n1  https://storage.googleapis.com/joshtalks-data-...  \n2  https://storage.googleapis.com/joshtalks-data-...  \n3  https://storage.googleapis.com/joshtalks-data-...  \n4  https://storage.googleapis.com/joshtalks-data-...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>recording_id</th>\n      <th>language</th>\n      <th>duration</th>\n      <th>rec_url_gcp</th>\n      <th>transcription_url_gcp</th>\n      <th>metadata_url_gcp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>245746</td>\n      <td>825780</td>\n      <td>hi</td>\n      <td>443</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>291038</td>\n      <td>825727</td>\n      <td>hi</td>\n      <td>443</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>246004</td>\n      <td>988596</td>\n      <td>hi</td>\n      <td>475</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>93626</td>\n      <td>990175</td>\n      <td>hi</td>\n      <td>475</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>286851</td>\n      <td>526266</td>\n      <td>hi</td>\n      <td>522</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"!pip install -q datasets transformers accelerate torchaudio jiwer librosa soundfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:46:30.444327Z","iopub.execute_input":"2026-02-19T12:46:30.444706Z","iopub.status.idle":"2026-02-19T12:46:37.582089Z","shell.execute_reply.started":"2026-02-19T12:46:30.444679Z","shell.execute_reply":"2026-02-19T12:46:37.580519Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"#Fixing broken urls\ndf[\"trans_url_fixed\"]=df[\"transcription_url_gcp\"].str.replace(\"joshtalks-data-collection/hq_data/hi/\", \"upload_goai/\", regex=False)\ndf[\"audio_url_fixed\"]=df[\"rec_url_gcp\"].str.replace(\"joshtalks-data-collection/hq_data/hi/\", \"upload_goai/\", regex=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:46:37.588247Z","iopub.execute_input":"2026-02-19T12:46:37.589357Z","iopub.status.idle":"2026-02-19T12:46:37.605992Z","shell.execute_reply.started":"2026-02-19T12:46:37.589314Z","shell.execute_reply":"2026-02-19T12:46:37.604981Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:46:37.607264Z","iopub.execute_input":"2026-02-19T12:46:37.607842Z","iopub.status.idle":"2026-02-19T12:46:37.642577Z","shell.execute_reply.started":"2026-02-19T12:46:37.607780Z","shell.execute_reply":"2026-02-19T12:46:37.641541Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"     user_id  recording_id language  duration  \\\n0     245746        825780       hi       443   \n1     291038        825727       hi       443   \n2     246004        988596       hi       475   \n3      93626        990175       hi       475   \n4     286851        526266       hi       522   \n..       ...           ...      ...       ...   \n99    278010        753435       hi       589   \n100   413240       1021370       hi      1194   \n101    11057       1020918       hi      1194   \n102    93299        840793       hi      1146   \n103   350216        840781       hi      1146   \n\n                                           rec_url_gcp  \\\n0    https://storage.googleapis.com/joshtalks-data-...   \n1    https://storage.googleapis.com/joshtalks-data-...   \n2    https://storage.googleapis.com/joshtalks-data-...   \n3    https://storage.googleapis.com/joshtalks-data-...   \n4    https://storage.googleapis.com/joshtalks-data-...   \n..                                                 ...   \n99   https://storage.googleapis.com/joshtalks-data-...   \n100  https://storage.googleapis.com/joshtalks-data-...   \n101  https://storage.googleapis.com/joshtalks-data-...   \n102  https://storage.googleapis.com/joshtalks-data-...   \n103  https://storage.googleapis.com/joshtalks-data-...   \n\n                                 transcription_url_gcp  \\\n0    https://storage.googleapis.com/joshtalks-data-...   \n1    https://storage.googleapis.com/joshtalks-data-...   \n2    https://storage.googleapis.com/joshtalks-data-...   \n3    https://storage.googleapis.com/joshtalks-data-...   \n4    https://storage.googleapis.com/joshtalks-data-...   \n..                                                 ...   \n99   https://storage.googleapis.com/joshtalks-data-...   \n100  https://storage.googleapis.com/joshtalks-data-...   \n101  https://storage.googleapis.com/joshtalks-data-...   \n102  https://storage.googleapis.com/joshtalks-data-...   \n103  https://storage.googleapis.com/joshtalks-data-...   \n\n                                      metadata_url_gcp  \\\n0    https://storage.googleapis.com/joshtalks-data-...   \n1    https://storage.googleapis.com/joshtalks-data-...   \n2    https://storage.googleapis.com/joshtalks-data-...   \n3    https://storage.googleapis.com/joshtalks-data-...   \n4    https://storage.googleapis.com/joshtalks-data-...   \n..                                                 ...   \n99   https://storage.googleapis.com/joshtalks-data-...   \n100  https://storage.googleapis.com/joshtalks-data-...   \n101  https://storage.googleapis.com/joshtalks-data-...   \n102  https://storage.googleapis.com/joshtalks-data-...   \n103  https://storage.googleapis.com/joshtalks-data-...   \n\n                                       trans_url_fixed  \\\n0    https://storage.googleapis.com/upload_goai/967...   \n1    https://storage.googleapis.com/upload_goai/967...   \n2    https://storage.googleapis.com/upload_goai/114...   \n3    https://storage.googleapis.com/upload_goai/114...   \n4    https://storage.googleapis.com/upload_goai/639...   \n..                                                 ...   \n99   https://storage.googleapis.com/upload_goai/887...   \n100  https://storage.googleapis.com/upload_goai/118...   \n101  https://storage.googleapis.com/upload_goai/118...   \n102  https://storage.googleapis.com/upload_goai/983...   \n103  https://storage.googleapis.com/upload_goai/983...   \n\n                                       audio_url_fixed  \n0    https://storage.googleapis.com/upload_goai/967...  \n1    https://storage.googleapis.com/upload_goai/967...  \n2    https://storage.googleapis.com/upload_goai/114...  \n3    https://storage.googleapis.com/upload_goai/114...  \n4    https://storage.googleapis.com/upload_goai/639...  \n..                                                 ...  \n99   https://storage.googleapis.com/upload_goai/887...  \n100  https://storage.googleapis.com/upload_goai/118...  \n101  https://storage.googleapis.com/upload_goai/118...  \n102  https://storage.googleapis.com/upload_goai/983...  \n103  https://storage.googleapis.com/upload_goai/983...  \n\n[104 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>recording_id</th>\n      <th>language</th>\n      <th>duration</th>\n      <th>rec_url_gcp</th>\n      <th>transcription_url_gcp</th>\n      <th>metadata_url_gcp</th>\n      <th>trans_url_fixed</th>\n      <th>audio_url_fixed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>245746</td>\n      <td>825780</td>\n      <td>hi</td>\n      <td>443</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/upload_goai/967...</td>\n      <td>https://storage.googleapis.com/upload_goai/967...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>291038</td>\n      <td>825727</td>\n      <td>hi</td>\n      <td>443</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/upload_goai/967...</td>\n      <td>https://storage.googleapis.com/upload_goai/967...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>246004</td>\n      <td>988596</td>\n      <td>hi</td>\n      <td>475</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/upload_goai/114...</td>\n      <td>https://storage.googleapis.com/upload_goai/114...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>93626</td>\n      <td>990175</td>\n      <td>hi</td>\n      <td>475</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/upload_goai/114...</td>\n      <td>https://storage.googleapis.com/upload_goai/114...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>286851</td>\n      <td>526266</td>\n      <td>hi</td>\n      <td>522</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/upload_goai/639...</td>\n      <td>https://storage.googleapis.com/upload_goai/639...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>278010</td>\n      <td>753435</td>\n      <td>hi</td>\n      <td>589</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/upload_goai/887...</td>\n      <td>https://storage.googleapis.com/upload_goai/887...</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>413240</td>\n      <td>1021370</td>\n      <td>hi</td>\n      <td>1194</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/upload_goai/118...</td>\n      <td>https://storage.googleapis.com/upload_goai/118...</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>11057</td>\n      <td>1020918</td>\n      <td>hi</td>\n      <td>1194</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/upload_goai/118...</td>\n      <td>https://storage.googleapis.com/upload_goai/118...</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>93299</td>\n      <td>840793</td>\n      <td>hi</td>\n      <td>1146</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/upload_goai/983...</td>\n      <td>https://storage.googleapis.com/upload_goai/983...</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>350216</td>\n      <td>840781</td>\n      <td>hi</td>\n      <td>1146</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n      <td>https://storage.googleapis.com/upload_goai/983...</td>\n      <td>https://storage.googleapis.com/upload_goai/983...</td>\n    </tr>\n  </tbody>\n</table>\n<p>104 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"#dropping the columns that are not required\ndf.drop([\"user_id\",\t\"recording_id\",\t\"language\",\t\"duration\", \"rec_url_gcp\",\"transcription_url_gcp\", \"metadata_url_gcp\"],axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:46:37.643915Z","iopub.execute_input":"2026-02-19T12:46:37.644325Z","iopub.status.idle":"2026-02-19T12:46:37.664918Z","shell.execute_reply.started":"2026-02-19T12:46:37.644269Z","shell.execute_reply":"2026-02-19T12:46:37.663940Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:46:37.666765Z","iopub.execute_input":"2026-02-19T12:46:37.667040Z","iopub.status.idle":"2026-02-19T12:46:37.691323Z","shell.execute_reply.started":"2026-02-19T12:46:37.667009Z","shell.execute_reply":"2026-02-19T12:46:37.690404Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                                       trans_url_fixed  \\\n0    https://storage.googleapis.com/upload_goai/967...   \n1    https://storage.googleapis.com/upload_goai/967...   \n2    https://storage.googleapis.com/upload_goai/114...   \n3    https://storage.googleapis.com/upload_goai/114...   \n4    https://storage.googleapis.com/upload_goai/639...   \n..                                                 ...   \n99   https://storage.googleapis.com/upload_goai/887...   \n100  https://storage.googleapis.com/upload_goai/118...   \n101  https://storage.googleapis.com/upload_goai/118...   \n102  https://storage.googleapis.com/upload_goai/983...   \n103  https://storage.googleapis.com/upload_goai/983...   \n\n                                       audio_url_fixed  \n0    https://storage.googleapis.com/upload_goai/967...  \n1    https://storage.googleapis.com/upload_goai/967...  \n2    https://storage.googleapis.com/upload_goai/114...  \n3    https://storage.googleapis.com/upload_goai/114...  \n4    https://storage.googleapis.com/upload_goai/639...  \n..                                                 ...  \n99   https://storage.googleapis.com/upload_goai/887...  \n100  https://storage.googleapis.com/upload_goai/118...  \n101  https://storage.googleapis.com/upload_goai/118...  \n102  https://storage.googleapis.com/upload_goai/983...  \n103  https://storage.googleapis.com/upload_goai/983...  \n\n[104 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trans_url_fixed</th>\n      <th>audio_url_fixed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://storage.googleapis.com/upload_goai/967...</td>\n      <td>https://storage.googleapis.com/upload_goai/967...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://storage.googleapis.com/upload_goai/967...</td>\n      <td>https://storage.googleapis.com/upload_goai/967...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://storage.googleapis.com/upload_goai/114...</td>\n      <td>https://storage.googleapis.com/upload_goai/114...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://storage.googleapis.com/upload_goai/114...</td>\n      <td>https://storage.googleapis.com/upload_goai/114...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://storage.googleapis.com/upload_goai/639...</td>\n      <td>https://storage.googleapis.com/upload_goai/639...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>https://storage.googleapis.com/upload_goai/887...</td>\n      <td>https://storage.googleapis.com/upload_goai/887...</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>https://storage.googleapis.com/upload_goai/118...</td>\n      <td>https://storage.googleapis.com/upload_goai/118...</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>https://storage.googleapis.com/upload_goai/118...</td>\n      <td>https://storage.googleapis.com/upload_goai/118...</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>https://storage.googleapis.com/upload_goai/983...</td>\n      <td>https://storage.googleapis.com/upload_goai/983...</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>https://storage.googleapis.com/upload_goai/983...</td>\n      <td>https://storage.googleapis.com/upload_goai/983...</td>\n    </tr>\n  </tbody>\n</table>\n<p>104 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"import os\nos.makedirs(\"audio_raw\", exist_ok=True)\nos.makedirs(\"audio_16k\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:46:37.692908Z","iopub.execute_input":"2026-02-19T12:46:37.693216Z","iopub.status.idle":"2026-02-19T12:46:37.711032Z","shell.execute_reply.started":"2026-02-19T12:46:37.693188Z","shell.execute_reply":"2026-02-19T12:46:37.710017Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"\nimport urllib.request\nimport librosa\nimport soundfile as sf\nfrom tqdm import tqdm\n\nprocessed_data=[]\n\nfor i, row in tqdm(df.iterrows(), total=len(df)):\n  try:\n    #download transcription\n    trans_url=row[\"trans_url_fixed\"]\n    r=requests.get(trans_url, timeout=10)\n    if r.status_code!=200:\n      continue\n\n    segments=r.json()\n    full_text=\" \".join([s[\"text\"] for s in segments])\n\n    #download audio\n    audio_url=row[\"audio_url_fixed\"]\n    raw_path=f\"audio_raw/{i}.wav\"\n    urllib.request.urlretrieve(audio_url, raw_path)\n\n    #conver to 16kHz\n    audio, sr=librosa.load(raw_path, sr=16000)\n    processed_path=f\"audio_16k/{i}.wav\"\n    sf.write(processed_path, audio, 16000)\n\n    #store result\n    processed_data.append({\n        \"audio\": processed_path,\n        \"text\":full_text\n    })\n  except Exception as e:\n    print(\"Error at row: \",i,\": \",e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T12:46:37.713503Z","iopub.execute_input":"2026-02-19T12:46:37.713928Z","iopub.status.idle":"2026-02-19T13:02:33.140420Z","shell.execute_reply.started":"2026-02-19T12:46:37.713881Z","shell.execute_reply":"2026-02-19T13:02:33.136921Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 104/104 [15:55<00:00,  9.19s/it]\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"#converting this data into a dataframe\nfinal_df=pd.DataFrame(processed_data)\nfinal_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:02:33.147133Z","iopub.execute_input":"2026-02-19T13:02:33.148211Z","iopub.status.idle":"2026-02-19T13:02:33.192019Z","shell.execute_reply.started":"2026-02-19T13:02:33.148151Z","shell.execute_reply":"2026-02-19T13:02:33.190784Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"             audio                                               text\n0  audio_16k/0.wav  अब काफी अच्छा होता है क्योंकि उनकी जनसंख्या बह...\n1  audio_16k/1.wav  जी जी जी जी जी । जी जी जी हां उधर हां जी हा हा...\n2  audio_16k/2.wav  लेकिन हम लोग इसे छुपछुप के लोगों के घर जाकर खे...\n3  audio_16k/3.wav  जी जी जी जी जी मेरे तो जैसे बहुत सारी यादे हैं...\n4  audio_16k/4.wav  हां जी पहले बात करते हैं विवाह की तो इस मुवी म...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_16k/0.wav</td>\n      <td>अब काफी अच्छा होता है क्योंकि उनकी जनसंख्या बह...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_16k/1.wav</td>\n      <td>जी जी जी जी जी । जी जी जी हां उधर हां जी हा हा...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_16k/2.wav</td>\n      <td>लेकिन हम लोग इसे छुपछुप के लोगों के घर जाकर खे...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_16k/3.wav</td>\n      <td>जी जी जी जी जी मेरे तो जैसे बहुत सारी यादे हैं...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_16k/4.wav</td>\n      <td>हां जी पहले बात करते हैं विवाह की तो इस मुवी म...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:02:33.193635Z","iopub.execute_input":"2026-02-19T13:02:33.194198Z","iopub.status.idle":"2026-02-19T13:02:38.451688Z","shell.execute_reply.started":"2026-02-19T13:02:33.194155Z","shell.execute_reply":"2026-02-19T13:02:38.450422Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.3)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.3.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (1.4.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.28.1)\nRequirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.5.4)\nRequirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.21.1)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (4.12.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.24.0->datasets) (8.3.1)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"from datasets import Dataset\ndataset=Dataset.from_pandas(final_df)\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:02:38.453822Z","iopub.execute_input":"2026-02-19T13:02:38.454211Z","iopub.status.idle":"2026-02-19T13:02:38.548638Z","shell.execute_reply.started":"2026-02-19T13:02:38.454170Z","shell.execute_reply":"2026-02-19T13:02:38.547142Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['audio', 'text'],\n    num_rows: 104\n})"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"#converting audio to proper format since whisper needs audio in a specific format\nfrom datasets import Audio\ndataset=dataset.cast_column(\"audio\", Audio(sampling_rate=16000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:02:38.554351Z","iopub.execute_input":"2026-02-19T13:02:38.554748Z","iopub.status.idle":"2026-02-19T13:02:38.570490Z","shell.execute_reply.started":"2026-02-19T13:02:38.554718Z","shell.execute_reply":"2026-02-19T13:02:38.569473Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"### Now, the dataset is ready for training\nConstructed a structured dataset by downloading audio files,resampling to 16000 Hz and converting the data into a proper dataset which will now be suitable for Whisper fine-tuning.","metadata":{}},{"cell_type":"markdown","source":"# Question 1: Part B","metadata":{}},{"cell_type":"code","source":"from transformers import WhisperProcessor, WhisperForConditionalGeneration\n\nmodel_name=\"openai/whisper-small\"\nprocessor=WhisperProcessor.from_pretrained(model_name)\nmodel=WhisperForConditionalGeneration.from_pretrained(model_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:02:38.572119Z","iopub.execute_input":"2026-02-19T13:02:38.573000Z","iopub.status.idle":"2026-02-19T13:02:42.090358Z","shell.execute_reply.started":"2026-02-19T13:02:38.572932Z","shell.execute_reply":"2026-02-19T13:02:42.089350Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/479 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"150eda432b474f5fa72f1f797eb01839"}},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"!pip install -q huggingface_hub datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:02:42.091675Z","iopub.execute_input":"2026-02-19T13:02:42.092080Z","iopub.status.idle":"2026-02-19T13:02:46.695772Z","shell.execute_reply.started":"2026-02-19T13:02:42.092029Z","shell.execute_reply":"2026-02-19T13:02:46.694315Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Use a pipeline as a high-level helper\nfrom transformers import pipeline\n\npipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:02:46.697829Z","iopub.execute_input":"2026-02-19T13:02:46.698942Z","iopub.status.idle":"2026-02-19T13:02:49.224956Z","shell.execute_reply.started":"2026-02-19T13:02:46.698903Z","shell.execute_reply":"2026-02-19T13:02:49.223730Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/479 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2402e190db30481b9357a45cda9d5a89"}},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n\nprocessor = AutoProcessor.from_pretrained(\"openai/whisper-small\")\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:02:49.226578Z","iopub.execute_input":"2026-02-19T13:02:49.227022Z","iopub.status.idle":"2026-02-19T13:02:52.574682Z","shell.execute_reply.started":"2026-02-19T13:02:49.226992Z","shell.execute_reply":"2026-02-19T13:02:52.573491Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/479 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"015ae6dd9d234bd7972bd2de2fdcf13d"}},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"#Converting raw data into whisper training format\nfrom transformers import AutoProcessor\n\nprocessor = AutoProcessor.from_pretrained(\"openai/whisper-small\")\n\ndef prepare_dataset(batch):\n    audio = batch[\"audio\"]\n\n    batch[\"input_features\"] = processor.feature_extractor(\n        audio[\"array\"],\n        sampling_rate=audio[\"sampling_rate\"]\n    ).input_features[0]\n\n    batch[\"labels\"] = processor.tokenizer(\n        batch[\"text\"],\n        max_length=448,\n        truncation=True\n    ).input_ids\n\n\n    return batch\n\ndataset = dataset.map(prepare_dataset)\ndataset=dataset.remove_columns([\"audio\", \"text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:02:52.576297Z","iopub.execute_input":"2026-02-19T13:02:52.576747Z","iopub.status.idle":"2026-02-19T13:03:16.741702Z","shell.execute_reply.started":"2026-02-19T13:02:52.576718Z","shell.execute_reply":"2026-02-19T13:03:16.740533Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/104 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2450c8a7cc924684a8bbc374ff486961"}},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"#creating a pytorch dataloader\nfrom transformers import TrainingArguments\ntraining_args=TrainingArguments(\n    output_dir=\"./whisper-finetuned\",\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=2,\n    learning_rate=1e-5,\n    max_steps=500,\n    logging_steps=10,\n    save_steps=100,\n    fp16=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:03:16.744072Z","iopub.execute_input":"2026-02-19T13:03:16.744420Z","iopub.status.idle":"2026-02-19T13:03:16.755825Z","shell.execute_reply.started":"2026-02-19T13:03:16.744335Z","shell.execute_reply":"2026-02-19T13:03:16.754578Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\ndataset.set_format(type=\"torch\")\n\ntrain_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:03:16.757399Z","iopub.execute_input":"2026-02-19T13:03:16.757834Z","iopub.status.idle":"2026-02-19T13:03:16.783928Z","shell.execute_reply.started":"2026-02-19T13:03:16.757780Z","shell.execute_reply":"2026-02-19T13:03:16.782722Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:03:16.785504Z","iopub.execute_input":"2026-02-19T13:03:16.785887Z","iopub.status.idle":"2026-02-19T13:03:16.815092Z","shell.execute_reply.started":"2026-02-19T13:03:16.785848Z","shell.execute_reply":"2026-02-19T13:03:16.814053Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"WhisperForConditionalGeneration(\n  (model): WhisperModel(\n    (encoder): WhisperEncoder(\n      (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n      (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n      (embed_positions): Embedding(1500, 768)\n      (layers): ModuleList(\n        (0-11): 12 x WhisperEncoderLayer(\n          (self_attn): WhisperAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): WhisperDecoder(\n      (embed_tokens): Embedding(51865, 768, padding_idx=50257)\n      (embed_positions): WhisperPositionalEmbedding(448, 768)\n      (layers): ModuleList(\n        (0-11): 12 x WhisperDecoderLayer(\n          (self_attn): WhisperAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): WhisperAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (proj_out): Linear(in_features=768, out_features=51865, bias=False)\n)"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:03:16.816345Z","iopub.execute_input":"2026-02-19T13:03:16.816679Z","iopub.status.idle":"2026-02-19T13:03:16.861689Z","shell.execute_reply.started":"2026-02-19T13:03:16.816650Z","shell.execute_reply":"2026-02-19T13:03:16.860553Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"def collate_fn(batch):\n    input_features = torch.stack([x[\"input_features\"] for x in batch])\n\n    labels = [x[\"labels\"] for x in batch]\n\n    labels = processor.tokenizer.pad(\n        {\"input_ids\": labels},\n        return_tensors=\"pt\"\n    ).input_ids\n\n    labels[labels == processor.tokenizer.pad_token_id] = -100\n\n    return {\n        \"input_features\": input_features,\n        \"labels\": labels\n    }\n\ntrain_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:03:16.863074Z","iopub.execute_input":"2026-02-19T13:03:16.863504Z","iopub.status.idle":"2026-02-19T13:03:16.871236Z","shell.execute_reply.started":"2026-02-19T13:03:16.863461Z","shell.execute_reply":"2026-02-19T13:03:16.870013Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"model.train()\n\nfor epoch in range(3):\n    print(f\"Epoch {epoch+1}\")\n    total_loss = 0\n\n    for batch in tqdm(train_loader):\n        input_features = batch[\"input_features\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(input_features=input_features, labels=labels)\n        loss = outputs.loss\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        total_loss += loss.item()\n\n    print(\"Average Loss:\", total_loss / len(train_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:03:16.872714Z","iopub.execute_input":"2026-02-19T13:03:16.873101Z","iopub.status.idle":"2026-02-19T14:28:29.156304Z","shell.execute_reply.started":"2026-02-19T13:03:16.873061Z","shell.execute_reply":"2026-02-19T14:28:29.153197Z"}},"outputs":[{"name":"stdout","text":"Epoch 1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26/26 [29:50<00:00, 68.88s/it]\n","output_type":"stream"},{"name":"stdout","text":"Average Loss: 1.527741482624641\nEpoch 2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26/26 [27:43<00:00, 63.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"Average Loss: 1.227468660244575\nEpoch 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26/26 [27:37<00:00, 63.76s/it]","output_type":"stream"},{"name":"stdout","text":"Average Loss: 1.081710207920808\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"save_path = \"/kaggle/working/whisper_finetuned\"\n\nos.makedirs(save_path, exist_ok=True)\n\nmodel.save_pretrained(save_path)\nprocessor.save_pretrained(save_path)\n\nprint(\"Model saved successfully at:\", save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T14:28:29.161347Z","iopub.execute_input":"2026-02-19T14:28:29.161982Z","iopub.status.idle":"2026-02-19T14:28:31.125722Z","shell.execute_reply.started":"2026-02-19T14:28:29.161926Z","shell.execute_reply":"2026-02-19T14:28:31.124745Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245beac5604f4b1ab00c346bd7e2fbe2"}},"metadata":{}},{"name":"stdout","text":"Model saved successfully at: /kaggle/working/whisper_finetuned\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"from jiwer import wer\nfrom tqdm import tqdm\nfrom transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\ndevice=\"cpu\"\n\nmodel=AutoModelForSpeechSeq2Seq.from_pretrained(\"/kaggle/working/whisper_finetuned\")\nprocessor=AutoProcessor.from_pretrained(\"/kaggle/working/whisper_finetuned\")\n\nsubset=dataset.select(range(20))\n\npred=[]\nref=[]\n\nfor sample in tqdm(subset):\n    input_features=sample[\"input_features\"].unsqueeze(0)\n    with torch.no_grad():\n        predicted_ids=model.generate(input_features)\n    pred_text=processor.decode(predicted_ids[0], skip_special_tokens=True)\n    ref_text=processor.decode(sample[\"labels\"], skip_special_tokens=True)\n    pred.append(pred_text)\n    ref.append(ref_text)\nwer_score=wer(ref, pred)\nprint(\"WER of dataset: \",wer_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T14:47:51.844468Z","iopub.execute_input":"2026-02-19T14:47:51.845593Z","iopub.status.idle":"2026-02-19T15:03:56.759811Z","shell.execute_reply.started":"2026-02-19T14:47:51.845550Z","shell.execute_reply":"2026-02-19T15:03:56.758588Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/479 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57691e1227334e1db3a44c6ac444e2b6"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 20/20 [16:02<00:00, 48.15s/it]","output_type":"stream"},{"name":"stdout","text":"WER of dataset:  0.93419740777667\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":63},{"cell_type":"markdown","source":"# Question 2","metadata":{}},{"cell_type":"code","source":"import os\n\nos.listdir(\"/kaggle/working\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T16:25:38.213096Z","iopub.execute_input":"2026-02-19T16:25:38.213910Z","iopub.status.idle":"2026-02-19T16:25:38.222118Z","shell.execute_reply.started":"2026-02-19T16:25:38.213858Z","shell.execute_reply":"2026-02-19T16:25:38.220924Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['.virtual_documents']"},"metadata":{}}],"execution_count":2}]}